Machine Learning Assignment
H.L. Oosting

12 januari 2017

Introduction
One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. In this report a model is found to predict the classe of the excersize.

Background
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement ??? a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

Plan of Action
According to the first week there are different staps in a prediction study: 1. define error rate 2. split data into testing and training 3. on the training set pick features with help of cross validation 4. on the training set pick prediction function with help of cross validation 5. apply once on the test set

Define error rate & Split data into testing and training

The first step, error rate can be determined when the model is finished and applied to the test set within the train set. What now is know that the “classe” has to determined. Classe has 5 options: A,B,C,D and E. The second stap is already done, there are two differents datasets for training and testing. The third step, picking features with the help of cross vallidation will now be done. The approach for this: 1. The training set will be split in a training and test set 2. Build a model on the training set 4. Evaluate on the test set 5. Repeat and average the estimated errors.

Before the set is split up the seed is set to make this research reproducible.

setwd("~/DSP/course 8/assignment")
list.files()
## [1] "assignment.Rmd"   "pml-testing.csv"  "pml-training.csv"
testing<-read.csv("pml-testing.csv")
training<-read.csv("pml-training.csv")
#head(training) for some exploratory data analysis
#str(training) for some exploratory data analysis

set.seed(12345)
library(caret)
## Loading required package: lattice
## Loading required package: ggplot2
inTrain<-createDataPartition(training$classe,p=0.6,list=FALSE)
train<-training[inTrain,]
test<-training[-inTrain,]
Build a model on the training set

Due to the huge amount of possible predictors, 160, there will be no plots of possible predictors. Some more exploratory data analysis is needed to decide what to do next. This is done with the summary(train), which not will be shown, due to the length. It is noticed that there are factor variables, empty colums (DIV/0), columns with NA values. So the first choice is to clean up the data by removing these non-informative columns. From here on a function will be build where a dataframe can be put in, so that all the changes we do, will also be done on the test dataframe.

train[train==""] <- NA
NArate <- apply(train, 2, function(x) sum(is.na(x)))/nrow(train)
# 2 stands for the columns
# NArate is the percentage of the NA rate, which you want under the 0.8
cleandata <- train[NArate==0]
There are still columns with factors in the dataframe, this is determined with the commando of str(cleandata), so these columns are subsetted and later added together.

dat_num<-cleandata[,sapply(cleandata,is.numeric)]
dat_factor<-cleandata[,sapply(cleandata,is.factor)]
summary(dat_factor)
##     user_name             cvtd_timestamp new_window  classe  
##  adelmo  :2372   05/12/2011 11:24: 937   no :11527   A:3348  
##  carlitos:1897   28/11/2011 14:14: 915   yes:  249   B:2279  
##  charles :2048   30/11/2011 17:11: 877               C:2054  
##  eurico  :1859   02/12/2011 13:34: 842               D:1930  
##  jeremy  :2039   05/12/2011 11:25: 838               E:2165  
##  pedro   :1561   02/12/2011 13:33: 815                       
##                  (Other)         :6552
From the factor part we can see that all those columns don’t tell that much. The name, date dont predict the classe and the new_window variable is mostly no. So we will leave those out. Also the X column is left out, this is just numbering of the rows.

dat_factor<-data.frame(classe=dat_factor$classe)
data_for_model<-cbind(dat_factor,dat_num)
data_for_model<-data_for_model[,-2]
Now are dataset is ready and models can be trained. The next models are considered: desicion tree (rpart) random forest (rf) boosting (gbm) linear discriminant analysis (lda)

The desicion tree:

model_rpart<-train(classe~.,data=data_for_model,method="rpart")
## Loading required package: rpart
confusionMatrix(predict(model_rpart,test),test$classe)
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1873  215  164  270   83
##          B  194  904  123  337  276
##          C  157  399 1081  615  232
##          D    0    0    0    0    0
##          E    8    0    0   64  851
## 
## Overall Statistics
##                                          
##                Accuracy : 0.6002         
##                  95% CI : (0.5892, 0.611)
##     No Information Rate : 0.2845         
##     P-Value [Acc > NIR] : < 2.2e-16      
##                                          
##                   Kappa : 0.4897         
##  Mcnemar's Test P-Value : < 2.2e-16      
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.8392   0.5955   0.7902   0.0000   0.5902
## Specificity            0.8696   0.8530   0.7834   1.0000   0.9888
## Pos Pred Value         0.7190   0.4929   0.4352      NaN   0.9220
## Neg Pred Value         0.9315   0.8979   0.9465   0.8361   0.9146
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2387   0.1152   0.1378   0.0000   0.1085
## Detection Prevalence   0.3320   0.2337   0.3166   0.0000   0.1176
## Balanced Accuracy      0.8544   0.7243   0.7868   0.5000   0.7895
The desiscion tree gives an Accuracy of 0.5495.

The random forest, I had to make the training set smaller, else my pc could not take it.

library(randomForest)
## randomForest 4.6-12
## Type rfNews() to see new features/changes/bug fixes.
## 
## Attaching package: 'randomForest'
## The following object is masked from 'package:ggplot2':
## 
##     margin
set.seed(123)
data_rf_train<-data_for_model[createDataPartition(data_for_model$classe,p=0.5,list=FALSE),]
data_rf_test<-data_for_model[-(createDataPartition(data_for_model$classe,p=0.5,list=FALSE)),]
model_rf<-randomForest(classe~., data_rf_train, prox=TRUE)
confusionMatrix(predict(model_rf,data_rf_test),data_rf_test$classe)
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1673    6    0    0    0
##          B    1 1133    2    0    0
##          C    0    0 1024    4    0
##          D    0    0    1  958    4
##          E    0    0    0    3 1078
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9964          
##                  95% CI : (0.9946, 0.9978)
##     No Information Rate : 0.2844          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.9955          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9994   0.9947   0.9971   0.9927   0.9963
## Specificity            0.9986   0.9994   0.9992   0.9990   0.9994
## Pos Pred Value         0.9964   0.9974   0.9961   0.9948   0.9972
## Neg Pred Value         0.9998   0.9987   0.9994   0.9986   0.9992
## Prevalence             0.2844   0.1935   0.1745   0.1639   0.1838
## Detection Rate         0.2842   0.1925   0.1739   0.1627   0.1831
## Detection Prevalence   0.2852   0.1930   0.1746   0.1636   0.1836
## Balanced Accuracy      0.9990   0.9971   0.9981   0.9959   0.9978
The random forest gives an accuracy of: 0.9963 Since this is so high and the boosting models take more then half an hour to progress I leave it to this.

Evaluate on the test set
Now to determine the Accuracy:

confusionMatrix(predict(model_rf,test),test$classe)
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2231    7    0    0    0
##          B    1 1509    8    0    0
##          C    0    2 1359   11    0
##          D    0    0    1 1268    8
##          E    0    0    0    7 1434
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9943          
##                  95% CI : (0.9923, 0.9958)
##     No Information Rate : 0.2845          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.9927          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9996   0.9941   0.9934   0.9860   0.9945
## Specificity            0.9988   0.9986   0.9980   0.9986   0.9989
## Pos Pred Value         0.9969   0.9941   0.9905   0.9930   0.9951
## Neg Pred Value         0.9998   0.9986   0.9986   0.9973   0.9988
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2843   0.1923   0.1732   0.1616   0.1828
## Detection Prevalence   0.2852   0.1935   0.1749   0.1628   0.1837
## Balanced Accuracy      0.9992   0.9963   0.9957   0.9923   0.9967
Predict the testing set
Now the model is used on the testing set.

predict(model_rf,testing)
##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
## Levels: A B C D E
